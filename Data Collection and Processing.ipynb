{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abe3cb02-d914-4b26-9d54-5fff2e8653e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6b550b5-c143-4584-a4ac-2898d435b791",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for AAPL saved successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for GOOG saved successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for MSFT saved successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for AMZN saved successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for META saved successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for TSLA saved successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for NVDA saved successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def calculate_technical_indicators(df):\n",
    "    # Calculate the 20-day EMA\n",
    "    df['20EMA'] = df['Close'].ewm(span=20, adjust=False).mean()\n",
    "\n",
    "    # Calculate the 50-day SMA\n",
    "    df['50SMA'] = df['Close'].rolling(window=50).mean()\n",
    "\n",
    "    # Calculate RSI (Relative Strength Index)\n",
    "    delta = df['Close'].diff()\n",
    "    gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()\n",
    "    rs = gain / loss\n",
    "    df['RSI'] = 100 - (100 / (1 + rs))\n",
    "\n",
    "    # Round off to 2 decimals\n",
    "    df = df.round(2)\n",
    "\n",
    "    return df\n",
    "\n",
    "def get_vix_data(start_date=\"2012-01-01\"):\n",
    "    # Download the VIX data from Yahoo Finance\n",
    "    vix_data = yf.download('^VIX', start=start_date)\n",
    "    # Keep only the 'Adj Close' column and rename it to 'VIX'\n",
    "    vix_data = vix_data[['Adj Close']].rename(columns={'Adj Close': 'VIX'}).round(2)\n",
    "    return vix_data\n",
    "\n",
    "def download_stock_data(ticker, start_date=\"2012-01-01\"):\n",
    "    # Download the stock data\n",
    "    stock_data = yf.download(ticker, start=start_date)\n",
    "    \n",
    "    # Add the company name as a new column\n",
    "    stock_data['company_name'] = ticker\n",
    "    \n",
    "    # Calculate technical indicators\n",
    "    stock_data = calculate_technical_indicators(stock_data)\n",
    "    \n",
    "    # Get the VIX data and merge it based on the Date index\n",
    "    vix_data = get_vix_data(start_date)\n",
    "    stock_data = stock_data.merge(vix_data, how='left', left_index=True, right_index=True)\n",
    "    \n",
    "    # Reset the index to move the date into a column\n",
    "    stock_data.reset_index(inplace=True)\n",
    "    \n",
    "    # Save the result to a CSV file\n",
    "    csv_filename = f'datasets/{ticker}_data.csv'\n",
    "    stock_data.to_csv(csv_filename, index=False)\n",
    "    \n",
    "    return stock_data\n",
    "\n",
    "# Example usage with dynamic tickers\n",
    "tickers = ['AAPL', 'GOOG', 'MSFT', 'AMZN', 'META', 'TSLA', 'NVDA']\n",
    "for ticker in tickers:\n",
    "    data = download_stock_data(ticker)\n",
    "    print(f\"Data for {ticker} saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02caefcd-28dd-4912-8f81-dae2c85d2bb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All data merged and saved to merged_stock_data.csv!\n"
     ]
    }
   ],
   "source": [
    "def merge_csv_files(directory='datasets'):\n",
    "    all_files = glob.glob(os.path.join(directory, \"*_data.csv\"))\n",
    "    dataframes = []\n",
    "    \n",
    "    for filename in all_files:\n",
    "        df = pd.read_csv(filename)\n",
    "        # Keep only relevant columns: company name and the rest of the data\n",
    "        df = df[['company_name', 'Date', 'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume', '20EMA', '50SMA', 'RSI', 'VIX']]\n",
    "        dataframes.append(df)\n",
    "    \n",
    "    if dataframes:  # Check if there's any DataFrame to concatenate\n",
    "        merged_data = pd.concat(dataframes, ignore_index=True)\n",
    "        merged_data.dropna(inplace=True)  # Remove rows with null values if needed\n",
    "        merged_data.to_csv('datasets/merged_stock_data.csv', index=False)\n",
    "        print(\"All data merged and saved to merged_stock_data.csv!\")\n",
    "    else:\n",
    "        print(\"No data files found to merge.\")\n",
    "\n",
    "# Call the merge function\n",
    "merge_csv_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9bca09-ae0e-476c-a9ee-a31fa03614c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256120b3-8c6a-48ec-b9fa-445cca3685ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
